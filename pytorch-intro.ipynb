{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scalars, vectors and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1416)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[[1, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(3.14159)\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor = torch.tensor([[[1,2,3]]])\n",
    "print(scalar)\n",
    "print(vector)\n",
    "print(matrix)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the dimensions of a tensor with ndim. You can use the square bracket trick to count the number of dimensions of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(scalar.ndim)\n",
    "print(vector.ndim)\n",
    "print(matrix.ndim)\n",
    "print(tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(scalar.shape)\n",
    "print(vector.shape)\n",
    "print(matrix.shape)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the float/int value from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141590118408203"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5561, 0.4331, 0.9004, 0.3433],\n",
       "        [0.3908, 0.8312, 0.3254, 0.2894],\n",
       "        [0.5037, 0.1795, 0.6925, 0.5698]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will usually instantiate our models with random tensors and have them be updated by gradient descent or another optimazation algorithm. However we might also want to start with all ones and zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_tensor = torch.ones(size=(3, 4))\n",
    "zeros_tensor = torch.zeros(size=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also worth noting that the default type in pytorch is float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use arange instead of the range function in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(0, 10)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to fill a tensor with the same shape as another tensor (useful for masking) we can use ones_like or zeros like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_zeros = torch.zeros_like(zero_to_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cuda is the datatype used for GPU computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common attricutes we may want to access are the dtype, device and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.int64\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(ten_zeros.device)\n",
    "print(ten_zeros.dtype)\n",
    "print(ten_zeros.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are really just a bunch of interconnected matrices/vectors with some mathematical expression connecting them. We can add, subtract, multiply (element wise & matrix multiplication), and divide tensors. You can use the regular operators in python or you can use the built in tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([10, 20, 30])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor + 10) # == torch.add(tensor, 10)\n",
    "print(tensor - 10) # == torch.sub(tensor, 10)\n",
    "print(tensor * 10) # == torch.mul(tensor, 10)\n",
    "print(tensor / 10) # == torch.div(tensor, 10)\n",
    "tensor_2 = torch.tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Multiplication is one of the most important concepts in Neural networks. Some basic rules of Matrix multiplication are:\n",
    "1) The inner dimensions of the two matrices must match. \n",
    "\n",
    "        (3,2) @ (3,2) will not work\n",
    "        (3,2) @ (2,3) will work\n",
    "2) The resulting matrix will be the dimensions of the outer matrix\n",
    "\n",
    "        (3,2) @ (2,3) will result in a matrix with dimensions (3,3)\n",
    "\n",
    "Keep in mind that matrix multiplication and element-wise matrix multiplication will return different results on the same matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "print(tensor * tensor)\n",
    "print(tensor.matmul(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common errors in deep learning is trying to multiply 2 matrices that can not be multiplies, and one of the easiest fixes to this is to transpose one of the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [3,2,1],[7, 8, 9]])\n",
    "# tensor.matmul(tensor) will throw an error\n",
    "print(tensor.shape)\n",
    "print(tensor.T.shape)\n",
    "# use the .T method to transpose the tensor so we can perform the matrix multiplication\n",
    "mul = tensor.matmul(tensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication is one of the most important topics to understand neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use some aggregate functions to find out information about our tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10)\n",
      "tensor(194)\n",
      "tensor(2)\n",
      "tensor(15)\n"
     ]
    }
   ],
   "source": [
    "print(mul.min())\n",
    "print(mul.max())\n",
    "#argmax and argmin return the index of the maximum and minimum value in a tensor\n",
    "print(mul.argmin())\n",
    "print(mul.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of useful methods to reshape tensors so they can be manipulated in other ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape takes an input tensor and a new shape and returns a new tensor with the new shape\n",
    "torch.reshape(tensor, (3, 4))\n",
    "#stack concatanates a sequence of tensors along a new dimension\n",
    "torch.stack([tensor, tensor])\n",
    "#squeeze squishes tensors along a dimension of size 1\n",
    "torch.squeeze(torch.tensor([[[1, 2, 3]]]))\n",
    "#There are a couple other methods that are useful for manipulating tensors, such as torch.cat, torch.chunk, torch.split, and torch.unbind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main use for these methods is to make tensors compatible for matrix multiplication for use in deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor indexing works pretty much the same as numpy array and list indexing with a couple differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [4, 5],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get all elements of one dimension we can use : and , to separate dimensions\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "#get all elements of the first dimension\n",
    "tensor[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch has built in functionality to convert tensors to and from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use from_numpy to convert numpy arrays to tensors, and .numpy() to convert from tensors to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([1, 2, 3])\n",
    "tensor = torch.from_numpy(array)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "array = tensor.numpy()\n",
    "array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomness\n",
    "\n",
    "We can use a manual seed to create reproducible random numbers for testing in pytorch using the manual seed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.9731, 0.5162, 0.0391, 0.1524],\n",
      "        [0.5041, 0.2316, 0.1970, 0.5104],\n",
      "        [0.6644, 0.0129, 0.7153, 0.3509]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.9731, 0.5162, 0.0391, 0.1524],\n",
      "        [0.5041, 0.2316, 0.1970, 0.5104],\n",
      "        [0.6644, 0.0129, 0.7153, 0.3509]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# # Set the random seed\n",
    "RANDOM_SEED=65 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Pytorch on a GPU\n",
    "\n",
    "Deep learning models take a long time to run, so  we usually want to use a GPU to run them. We can either use a virtual machine (google colab, AWS, etc...) or our own local GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 10:08:12 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.112                Driver Version: 537.42       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   33C    P8              N/A / ERR! |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        29      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#this command will show you if yo have a GPU available, I have a GTX 1050 on my laptop with 4gb of VRAM\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if we can run on our GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set our device to the GPU if it is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.device_count()\n",
    "#move our tensor to the GPU\n",
    "tensor = torch.tensor([1, 2, 3]).to(device)\n",
    "tensor.device\n",
    "#now our tensor is on the GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries like numpy and sklearn don't support running on the GPU, so we can use the .cpu() method to run our tensors back on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#make a copy of our tensor that can run on the CPU\n",
    "tensor_cpu = tensor.cpu()\n",
    "print(tensor.device)\n",
    "print(tensor_cpu.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0175],\n",
       "        [2.3386],\n",
       "        [1.9782],\n",
       "        [1.6978],\n",
       "        [1.9161],\n",
       "        [2.0249],\n",
       "        [1.9303]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(7,7)\n",
    "tensor_2 = torch.rand(1,7)\n",
    "tensor.matmul(tensor_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8542],\n",
       "        [1.9611],\n",
       "        [2.2884],\n",
       "        [3.0481],\n",
       "        [1.7067],\n",
       "        [2.5290],\n",
       "        [1.7989]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED=0\n",
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "tensor = torch.rand(7,7)\n",
    "tensor_2 = torch.rand(1,7)\n",
    "tensor.matmul(tensor_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3647, 0.4709],\n",
       "        [0.5184, 0.5617]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.set_rng_state(torch.ByteTensor(),device)\n",
    "torch.random.manual_seed(seed=1234)\n",
    "tensor = torch.rand(2,3).to(device)\n",
    "tensor_2 = torch.rand(2,3).to(device)\n",
    "tensor.matmul(tensor_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
